{
  "agent_id": "coder2",
  "task_id": "task_10",
  "files": [
    {
      "filename": "workflow_adaptation_engine.py",
      "purpose": "Implements adaptive algorithms that adjust to individual clinician workflows, handles variable scratch note formats, and learns from clinician corrections.",
      "priority": "high",
      "dependencies": [
        "scikit-learn",
        "pandas",
        "numpy"
      ],
      "key_functions": [
        "learn_clinician_preferences",
        "adapt_to_workflow",
        "predict_scratch_format",
        "adjust_output_structure",
        "update_user_profile"
      ],
      "estimated_lines": 350,
      "complexity": "high"
    }
  ],
  "project_info": {
    "project_name": "Clinical_Note_Generation_LLM_Evaluation_Framework",
    "project_type": "nlp",
    "description": "A comprehensive evaluation framework for assessing LLM performance in clinical documentation generation, specifically focusing on SOAP note creation from scratch notes in pediatric occupational therapy settings. The system addresses sociotechnical challenges by implementing adaptive workflows, clinician autonomy features, and mutual learning mechanisms between AI systems and healthcare providers.",
    "key_algorithms": [
      "Few-shot Learning with Domain Adaptation",
      "LoRA Fine-tuning on Clinical Data",
      "SOAP Note Structure Recognition",
      "Clinical Entity Extraction and Classification",
      "Workflow Adaptation Algorithms",
      "Trust Calibration Mechanisms"
    ],
    "main_libraries": [
      "transformers",
      "torch",
      "peft",
      "datasets",
      "spacy",
      "scikit-learn",
      "pandas",
      "numpy",
      "nltk",
      "seqeval",
      "accelerate",
      "wandb"
    ]
  },
  "paper_content": "PDF: cs.HC_2509.04340v1_Write-on-Paper-Wrong-in-Practice-Why-LLMs-Still-.pdf\nChunk: 1/1\n==================================================\n\n--- Page 1 ---\nWRITE ON PAPER , W RONG IN PRACTICE : W HYLLM SSTILL\nSTRUGGLE WITH WRITING CLINICAL NOTES\nKristina L. Kupferschmidt\nSchool of Mathematical and Computational Sciences\nUniversity of Prince Edward Island\nCanada\nkkupferschmidt@upei.caKieran O\u2019Doherty\nDepartment of Psychology\nUniversity of Guelph\nCanada\nohdertk@uoguelph.caJoshua A. Skorburg\nDepartment of Philosophy\nUniversity of Guelph\nCanada\nskorburg@uoguelph.ca\nSeptember 5, 2025\nThis paper has been accepted to AIES 2025.\nABSTRACT\nLarge Language Models (LLMs) are often proposed as tools to streamline clinical documentation,\na task viewed as both high-volume and low-risk. However, even seemingly straightforward appli-\ncations of LLMs raise complex sociotechnical considerations to translate into practice. This case\nstudy, conducted at KidsAbility, a pediatric rehabilitation facility in Ontario, Canada examined the\nuse of LLMs to support occupational therapists in reducing documentation burden.We conducted a\nqualitative study involving 20 clinicians who participated in pilot programs using two AI technolo-\ngies: a general-purpose proprietary LLM and a bespoke model fine-tuned on proprietary historical\ndocumentation.\nOur findings reveal that documentation challenges are sociotechnical in nature, shaped by clinical\nworkflows, organizational policies, and system constraints. Four key themes emerged: (1) the\nheterogeneity of workflows, (2) the documentation burden is systemic and not directly linked to the\ncreation of any single type of documentation, (3) the need for flexible tools and clinician autonomy,\nand (4) effective implementation requires mutual learning between clinicians and AI systems.\nWhile LLMs show promise in easing documentation tasks, their success will depend on flexible,\nadaptive integration that supports clinician autonomy. Beyond technical performance, sustained\nadoption will require training programs and implementation strategies that reflect the complexity of\nclinical environments.\n1 Introduction\nLarge Language Models (LLMs) have been heralded as a turning point in healthcare. Popular tools like GPT-4 have\ndemonstrated performance on par with or exceeding physicians on benchmark evaluations such as the United States\nMedical Licensing Examination (USMLE) [Brin et al., 2023], and are already being deployed in applications ranging\nfrom patient triage to diagnostic support. The speed of adoption has been unprecedented, with healthcare systems,\nvendors, and startups racing to integrate LLMs into clinical workflows [Ma et al., 2024, Peterson Health Technology\nInstitute AI Taskforce, 2025]. This is coming to fruition in many ways, with health providers exploring LLMs as\nclinical assistants, scribes, and documentation tools. As adoption accelerates, these tools are increasingly positioned as\ntransformative for clinical practice. Yet amid bold predictions about replacing diagnosticians, a more grounded question\nremains: can these models reliably handle the \u201ceasy\u201d tasks? And if they can, will that performance hold up under the\ncomplexity of real-world settings?\nClinical documentation, especially when written in frequently used standard formats like SOAP (Subjective, Objective,\nAssessment, Plan) have been pitched as a low-risk and high-reward use case. SOAP notes are central to both carearXiv:2509.04340v1  [cs.HC]  4 Sep 2025\n\n--- Page 2 ---\nAPREPRINT - SEPTEMBER 5, 2025\ndelivery and legal documentation for many health fields but are often criticized for their repetitive and time-consuming\nnature. Because SOAP notes follow a widely taught structure and account for the bulk of therapists\u2019 record-keeping\ntime, they\u2019re often cast as \u201clow-hanging fruit\u201d for automation [Biswas and Talukdar, 2024].\nHowever, our study challenges that assumption. We present a detailed qualitative case study of a pilot program testing\nLLMs in a pediatric rehabilitation clinic. The goal was to reduce clinician documentation time by helping occupational\ntherapists generate SOAP notes more efficiently. In practice, clinicians begin with \u201cscratch notes\u201d (i.e. bullet points,\nmemory cues, or brief sentences) that are written during the patient interaction and transform them into the SOAP format\nafter the fact [Amenyo et al., 2025]. On paper, this task maps neatly onto current LLM capabilities: convert unstructured\ntext into a consistent, templated output. Yet, deployment and follow-up interviews revealed layers of friction such as\nformatting mismatches, user distrust, workflow misalignment, and perceived threats to clinician autonomy. These issues\nstem not from poor language generation, but from deeper, systemic mismatches between real-world documentation\npractices and user expectations of model behaviours.\nPrior research has explored both the potential and limitations of using LLMs for documentation. Some studies have\nfound success in using LLMs to summarize visit notes, translate clinical jargon for patients, or assist with discharge\nsummaries [Ma et al., 2024]. Yet even in these use cases, concerns persist about output quality, interpretability,\nalignment with clinician expectations, and the ability of AI systems to enhance, rather than disrupt, existing care\nworkflows.\nOur findings suggest that while LLMs may be technically capable of generating documentation, their real-world\neffectiveness depends on a web of sociotechnical factors: the variability of clinician workflows, the adaptability of\nAI interfaces, the depth of user training, and the policies governing documentation practices. In other words, even\nstructurally simple tasks require careful, context-aware implementation. Mollick [2025] promotes a similar sentiment,\nthat widespread enthusiasm for LLMs may not yield the broader organizational benefits it promises. In particular, he\nemphasizes that in order to realize meaningful gains from tools like LLMs, organizations need to treat adoption as a\nprocess of organizational learning rather than focusing on the technical roll out.\nWhile much of the discourse around AI ethics in healthcare has focused on fairness, transparency, and data provenance\nand privacy, there is a tendency to treat technical feasibility as a foregone conclusion [Satheakeerthy et al., 2025,\nOng et al., 2024]. Specifically, in the context of building trust in the end-user and what a \u201ctrustworthy\u201d system really\nconsists of [B\u00fcrger et al., 2024]. But, if even seemingly simple tasks like documentation remain difficult to implement\neffectively, then efficacy itself must be treated as an ethical concern. Deploying systems before they\u2019ve demonstrated\nconsistent utility in real clinical environments risks introducing not just inefficiency, but also harm through wasting\nclinician time, undermining trust, or producing documentation that is misaligned with standards of care.\nThe objective of this study was to assess the feasibility of using modern LLMs to reduce documentation burden in\npediatric occupational therapy. Although our analysis is grounded in this specialized setting, the lessons learned are\nbroadly applicable across healthcare domains. This case study makes three core contributions:\n1.It exposes the gap between LLM capabilities and their real-world clinical utility in documentation-heavy\nworkflows.\n2.It demonstrates how deployment failures often stem not from model performance alone, but from misalignments\nbetween tool design and the clinical context.\n3.It underscores that healthcare documentation remains an unsolved challenge, even for seemingly straightfor-\nward tasks.\nOur findings offer a revealing test case for evaluating LLM readiness in healthcare. If we cannot successfully automate\nroutine documentation, it raises critical concerns about deploying these models for more complex, high-stakes clinical\napplications.\n2 Background\n2.1 Adoption of LLMs in Healthcare\nThe integration of LLMs into healthcare has accelerated rapidly over the past several years [Ma et al., 2024, Peterson\nHealth Technology Institute AI Taskforce, 2025]. These models have been positioned as transformative tools capable\nof enhancing productivity, supporting clinical decision-making, and reducing administrative burdens. Among these\napplications, the generation of structured clinical notes has emerged as a popular and relatively straightforward use case.\nHowever, despite the technical feasibility, a number of critical challenges persist. Research has highlighted concerns\nabout model interpretability, trustworthiness, and fit with existing workflows [Farhat, 2024]. In some cases, the outputs\n2\n\n--- Page 3 ---\nAPREPRINT - SEPTEMBER 5, 2025\nfail to meet clinician expectations, either due to formatting mismatches, the use of inappropriate structuring (e.g.,\nsummaries instead of SOAP notes), or unexpected tone [Han et al., 2024]. These challenges can be further compounded\nby biases that are embedded in the training data used for these large-scale models, which can be particularly dangerous\nwhen applied to human behavior and groups that have historically been treated unjustly Farhat [2024].\nA growing body of work has begun to explore not just technical performance but the human and organizational factors\nshaping adoption. One particularly challenging aspect is establishing healthcare provider comfort and confidence with\nLLM use. For example, a study by Spotnitz et al. [2024] quantified the experience of medical professionals across three\naxes: (1) years of clinical training, (2) years of informatics training, and (3) hours of LLM use in the past 12 months.\nAmong diverse clinical experts with novice LLM experience, the majority felt that using LLMs to support clinical tasks\nsuch as translating technical reports into layperson summaries (n=21/30) and creating discharge summaries (n=20/30)\nwere appropriate use cases. However, tasks such as responding to patient questions about a technical report (n=7/30) or\nwriting full reports (n=7/30) were less accepted [Spotnitz et al., 2024].\nThis tension between the opportunity and hesitation of adoption also appears in qualitative studies. For instance, Ma\net al. [2024] conducted a qualitative study aiming to better understand the perceptions of mental health and AI experts\nwhen considering the integration of LLMs into the related field of mental health practice. Through semi-structured\ninterviews, a mixture of psychiatrists (n=12), mental health nurses (n=7), and AI in medicine researchers (n=2) were\nengaged to understand their perspectives on integrating these tools. Participants were particularly enthusiastic about the\npotential for LLMs to improve efficiency and quality of work, specifically referring to how LLMs could help support\nthe completion of routine text-generation tasks, freeing up more time and attention for patient-facing tasks. Another\nimportant finding concerned the prerequisites that should exist for integrating LLMs into the mental health field. These\nhighlighted the necessity of relevant training sessions to prepare professionals for current and proficient use of LLMs\nand, in general, the enhancement of digital literacy to support their continued use despite a rapidly changing landscape.\nFurthermore, clinicians cited concerns around creating proper guidelines for use and management, calling for clear\nprinciples that would ensure these tools are being used responsibly [Ma et al., 2024].\nMore specifically, some research has focused exclusively on using LLMs to enhance clinician productivity through\nsupporting clinical note generation. For example, [Han et al., 2024] proposed AscleAI and conducted an interview\nstudy exploring how LLMs could support clinicians in practice. In the settings tested, challenges such as completing\ndocumentation while simultaneously engaging with patients were frequently cited. Before the introduction of LLMs,\ncommon strategies to overcome these challenges included making corrections to notes immediately following the end\nof a session or using specific templates to reduce time spent writing during sessions. The outputs of the task seemed to\nbe of particular importance, where the results were met with inconsistent feelings. Many of the concerns surrounded a\nmismatch of clinician expectations and model outputs. For instance, some participants were frustrated that the outputs\nof AscleAI were not in the SOAP format but instead provided a summary. Furthermore, some clinicians found that the\ninherent structuring (i.e., sentence-based vs. bullet form) did not match their expectations for how they would like their\noutput notes to be formatted [Han et al., 2024].\nGiven this emphasis on efficiency, it is perhaps unsurprising that the proposed use of AI-based scribes has surged in\npopularity. Modern AI-based scribes tout the potential to passively record patient-provider interactions and convert\nthem into useful summarizations and documentation, simultaneously increasing patient volume while improving visit\nquality. Based on a recent report from the Peterson Health Technology Institute AI Taskforce [2025], approximately 60\nambient scribes are currently being applied in practice in the United States. The adoption of these scribes represents a\nsignificant deviation from the normal adoption pipeline of the industry, historically known for long implementation\ntimelines and cumbersome workflow changes. The report suggests mixed results along different axes of improving\nworkflows. Positive impacts have been observed for clinical burnout, cognitive load, and the downstream quality of\ngenerated notes. Mixed feedback was observed regarding clinician experience, time saved by technology adoption,\nand the avoidance of \u201cpajama time\" where clinicians complete documentation requirements outside of working hours\n[Peterson Health Technology Institute AI Taskforce, 2025].\n2.2 Nuances of Documentation in Pediatric Occupational Therapy\nPediatric occupational therapy services are often provided in multiple distinct environments, each with unique charac-\nteristics and challenges. For instance, younger pre-school aged children are often seen through in-center and virtual\nconsultations that are typically conducted with families present in a structured environment. Clinicians often work\nwith families to tailor interventions to each child\u2019s developmental needs, creating personalized treatment plans [Cahill\nand Beisbier, 2020]. In contrast, School-Based services offer in-school consultations without families present, in less\nstructured and more rapidly changing environments. These visits can range from specific one-to-one visits or universal\nclassroom visits where all students and educators are observed in parallel.\n3\n\n--- Page 4 ---\nAPREPRINT - SEPTEMBER 5, 2025\nDocumentation in occupational therapy is a structured process of recording client information, therapeutic interventions,\nand treatment outcomes. At the studied center, documentation took on several forms, which depend both on the program\nin which the clinician (i.e. In-Center vs. School-Based) worked in and the point of treatment for the client. Progress\nnotes are used across all visit types and are the only form of documentation legally required by the provincial OT\nregulatory body [Amenyo et al., 2025].\nDocumentation in healthcare settings, particularly in occupational therapy, serves multiple critical purposes beyond\nsimple record-keeping. The ultimate goal of this documentation is to provide comprehensive understanding of client\nabilities, progress, and limitations throughout their treatment journey; however, in practice this may not be the case. In\nits ideal form, effective documentation reflects all treatment stages from initial assessment to ongoing intervention. It\ncaptures not only physical aspects of therapy but also environmental and contextual factors affecting client participation\nin activities of daily living [Cahill and Beisbier, 2020]. Documentation acts as an essential communication tool among\nhealthcare providers, supporting coordinated care across interdisciplinary teams. Additionally, it provides a formal\nlegal and regulatory record that may be reviewed for accreditation purposes, used in legal proceedings, or examined for\nreimbursement claims [Gateley, 2015].\nWhile documentation remains a critical aspect of care, it has increasingly become a burden for healthcare providers at\nthe studied center. Both clinicians and management perceived that growing documentation demands were impacting the\norganization\u2019s ability to deliver services effectively. The center was facing service capacity issues, marked by long\nwaitlists and an inability to meet the rising demand for pediatric occupational therapy services. At the same time,\nanecdotal evidence suggested that clinician well being is suffering, with reports of burnout and difficulty keeping up\nwith administrative requirements. These concerns echo broader trends identified in recent reports\u2014such as one from\nthe Peterson Health Technology Institute AI Taskforce\u2014which link excessive documentation to provider burnout and\ndecreased system capacity [Peterson Health Technology Institute AI Taskforce, 2025].\n2.3 Case Study: Pediatric Occupational Therapy LLM Pilot Study\nOur study was completed in collaboration with KidsAbility, a pediatric rehabilitation center that provides comprehensive\nrehabilitation services across several professions including occupational therapy, speech-language pathology, and\nphysiotherapy. Within KidsAbility, Early Years (including Entry to School) and School Years programs are delivered\nprimarily in-center, whereas the School-Based Rehabilitation program operates directly within school environments.\nThe case study was part of a broader initiative to streamline documentation using LLMs, with the goal of enhancing\nservice delivery capacity and reducing wait times. To evaluate this, the team conducted a pilot study using LLMs\nto convert therapists\u2019 brief session notes (i.e., scratch notes) into structured clinical documentation [DiMaio, 2024].\nTo do so the technical team adapted foundation language models which resulted in a bespoke version based on the\nLlama 3 8B architecture that was created purely for the process of generating visit notes from scratch notes. Model\ntraining used thousands of de-identified historical SOAP-format progress notes, supplemented with few-shot\u2013prompted\nsynthetic scratch notes to create paired training examples. Fine-tuning employed LoRA adapters with domain-adaptive\npre-training to reduce overfitting, and the model was evaluated on a held-out test set before pilot deployment.\nTo evaluate both the effectiveness of this specific intervention and LLM utility more broadly ten occupational therapists\nparticipated in a comparative assessment period. In the initial phase, clinicians utilized a secure version of Microsoft\u2019s\nenterprise CoPilot program for three-weeks with a subsequent phase employing the custom-developed solution (three-\nweek duration) [DiMaio, 2024]. While the Llama 3 8B model is smaller than most commercial systems, it was\ndeliberately selected to limit overfitting during fine-tuning and to test the feasibility of a domain-specific model. For\ncomparison, clinicians also evaluated a large general-purpose model (Microsoft\u2019s enterprise CoPilot) under the same\nstudy conditions, attempting to distinguish size-related performance effects from broader sociotechnical factors.\n3 Methods\nIt is in this context that our study was implemented. We conducted 30 interviews with 20 clinical staff members at a\npediatric rehabilitation center in Ontario, Canada to learn about their perspectives on documentation and possibilities\nfor LLMs to assist with documentation tasks.\n3.1 Recruitment/Participants\nParticipants in the study were clinical staff working for the associated organization. They were recruited by center\nadministrative staff and referred to us for voluntary participation in the study. Participants were informed about the\nnature of the study and assured of confidentiality before they consented to take part in the study. In total, 20 clinicians\ntook part in this study.\n4\n\n--- Page 5 ---\nAPREPRINT - SEPTEMBER 5, 2025\nOf the 20 participants, 6 worked in the Early Years program (including Entry to School), 10 in the School-Based\nRehabilitation program, and 4 in the School Years program. The Early Years and School Years programs were delivered\nprimarily in-center, whereas the School-Based Rehabilitation program was delivered directly in school environments.\nParticipants\u2019 total years of practice (including experience prior to joining KidsAbility) ranged from 1 to 22 years\n(median = 10 years), representing a mix of junior, mid-career, and senior therapists. Ten participants took part in the\npilot study (4 Early Years, 4 School-Based Rehabilitation, 2 School Years), with experience ranging from 1 to 22 years.\nThe remaining 10 participants did not take part in the pilot (6 School-Based, 1 Early Years, and 2 School Years), with\nexperience ranging from 3 to 15 years.\n3.2 Procedures\nIndependent of this study, the center conducted a pilot workshop in which participants were introduced to two different\nLLMs and given instructions for how they could be used to assist with documentation tasks (see above section). Of the\n20 clinicians who participated in the present study, 10 had taken part in the pilot program, and 10 had not taken part in\nthe pilot program. Clinicians who had taken part in the pilot program were interviewed twice, once before and once\nafter the pilot program. Clinicians who had not taken part in the pilot program were interviewed only once.\nThe purpose of the semi-structured interviews was to understand the nature of the documentation burden on clinicians,\ntheir perspectives of the role of documentation in the context of their work, and their perspectives on the possible role\nof LLMs in helping to assist with documentation. Clinicians who had taken part in the pilot workshop were interviewed\ntwice so that they had the opportunity to express their views before and after being exposed to two LLMs currently\navailable to assist with documentation. In the interviews, clinicians were asked questions about their clinical practice,\nthe kinds of documentation required for their work, what kinds of notes they take and how they take notes, and how\nmuch time documentation takes. They were also asked about whether they had previously heard about applications of\nAI in healthcare more generally, whether they had experience with AI or LLM tools, and whether they thought tools\nlike ChatGPT could be appropriately used in clinical contexts. Interviews were conducted virtually and were recorded\nusing the built in Teams functionality through Microsoft360. Interviews ranged in length from 20 to 35 minutes and\nwere transcribed verbatim and verified by the research team.\n3.3 Analysis\nInterview transcripts were coded with the help of NVivo14. Braun and Clarke [2006, 2013] six-phase thematic coding\nprocess was followed to identify dominant themes in the interviews that identified the range of perspectives clinicians\nexpressed on the issue of documentation burdens, possible ways of mitigating this burden, and the specific use of\ngenerative AI and similar technologies in this regard.\n4 Results\nThematic analysis of our data revealed four primary themes:\n1. Clinical documentation in occupational therapy is highly heterogeneous\n2.The sociotechnical nature of challenges existing at the organization extend beyond the completion and creation\nof SOAP notes\n3. The need for flexibility and clinician autonomy\n4.The requirement of mutual learning on both the end of the clinician and the AI system to facilitate collaboration\n4.1 Theme 1: Heterogeneity in Documentation Workflows\nOur analysis revealed substantial variation in documentation workflows across the organization, specifically when we\ncompared conditions related to the underlying process of generating SOAP notes from scratch notes. Understanding\nthese workflows was essential to evaluating the potential for AI-assisted documentation. Documentation workflows\nvaried considerably from clinician to clinician but there are also notable differences in their anecdotal description of\nhow they complete their sessions, create scratch note or memory cues, and complete their finalized documentation. Very\ngenerally speaking the documentation process typically follows this progression:\n1. Within Session: Creation of scratch notes or memory cues\n2. Post Session: Conversion of scratch notes into formal documentation (SOAP notes)\n5\n\n--- Page 6 ---\nAPREPRINT - SEPTEMBER 5, 2025\nClinician accounts suggested that the execution of these tasks was influenced by both intrinsic and extrinsic factors.\nIntrinsic factors included prior work experience, professional training, and personal preferences for verbosity or\nstructure. Extrinsic factors encompassed the specific program they worked within, the type of visit, client characteristics,\nand scheduling constraints.\nA notable distinction was observed between clinicians working in the in-center programs (Early Years, including Entry\nto School, and School Years) and those in the School Based Rehabilitation program. One of the most significant\ndifferences involved the tools and conditions available for in-session documentation.\nClinicians in the in-center programs were able to make use of jot or scratch notes during or immediately after sessions.\nThese notes that were created either digitally or on paper were often more substantive and detailed. However, even\nwithin this program, the format and content of scratch notes remained highly individualized.\nIn contrast, clinicians in the School Based program frequently conducted sessions in less controlled environments, such\nas classrooms with multiple children present. These conditions limited their ability to use documentation tools during\nthe session. As a result, scratch notes -if created at all\u2014were generally minimal, serving primarily as memory aids\nrather than substantive written records. This environmental constraint significantly impacted the nature and quality of\nintermediate documentation and could have negative downstream impacts in a tool that was explicitly designed to map\nscratch notes to completed SOAP notes. Furthermore, in the School-Based program clinicians employ a tiered approach\nto care, where visits often consist of observing classroom settings rather than in a one-to-one session.\nThis contrast in session context and documentation opportunity is captured in the following reflection from a School-\nBased occupational therapist:\n\u201cSo I work almost 100% in schools. I don\u2019t do a lot of like one to one treatment, so I wouldn\u2019t have a\nkid for like a session like a clinician in center might, but I would either be embedded in the classroom\nand then like have a space to work ideally or I would like a rare occasions would pull a kid into like\na small space to do some work with, but for the most part I\u2019m in their classroom context or in like a\nseparate spot on the school working on something with that kid. \u201d -P08\nThe less predictable nature of School-Based work also shaped when documentation could occur. Early Years clinicians\noften had scheduled time between appointments to write notes. In contrast, School-Based clinicians faced variable\nschedules and frequent coordination with school staff.\nContinuing this point, Participant 08 explained how scheduling constraints affect documentation timing:\n\u201cSome schools will have me booked in like a classroom, but for the most part I sort of schedule it on\nthe fly so like I keep a running tally of things that I need to do in my head. Go and check in on those\nkids check in on their staff. See if there\u2019s anything new, any like priorities and then do that sort of\nfor several hours within the morning, and then by the time we hit about like 1:30-2 o\u2019clock, their\nbreak times are they\u2019re sort of winding down the day. And I have to start just doing all the paperwork\nassociated with that day. \u201d -P08\nThe main findings from this theme suggest that workflows and intermediate documentation artifacts are not only highly\npersonalized but are also deeply shaped by programmatic context. These variations include differences in scratch note\nstructure, the timing of documentation activities, and the use of shortcuts or templates to streamline note conversion.\nThe combination of these factors introduces a significant challenge for general-purpose or even bespoke LLM systems,\nas inconsistency in both input (scratch notes) and expected output (SOAP notes) reduces the likelihood of generating\nconsistently high-quality results.\n4.2 Theme 2: \u201cSOAP notes aren\u2019t the problem\u201d\nMany participants demonstrated a clear awareness of the broader challenges facing the organization. Our analysis\nrevealed that the core issues clinicians face are not rooted in the act of writing SOAP notes, but stem from a broader\nset of systemic and contextual factors. Some of the key factors include the heterogeneity of clinicians, organizational\npolicies and decisions, as well as technology factors.\nOne in-clinic therapist framed the issue plainly, shifting the focus away from writing toward broader workload\nchallenges:\n\u201cNo, I think if I had to tell you what I think the problem is, I don\u2019t think it\u2019s our ability to write, It\u2019s the\namount of things we have to do. \u201d -P03\n6\n\n--- Page 7 ---\nAPREPRINT - SEPTEMBER 5, 2025\nThis sentiment was echoed by another participant (P05), who initially approached the LLM documentation tool with\noptimism but later found it failed to address what they perceived to be the real bottleneck:\n\u201cI think I was intrigued by it at first and then the reality of it, I was like, it actually doesn\u2019t save me\ntime, It didn\u2019t save me time, in terms of the soap notes, anyways from that was my experience with it\nthat it was I think our other processes are extremely inefficient and you know but I think doing the\nsoap note isn\u2019t necessarily the thing that takes the time\u201d -P05\nAlthough many participants described a challenging relationship with documentation, they also expressed a sense of\npride, ownership, and value in the notes they created. Several emphasized that writing SOAP notes is a professional\nobligation governed by the College of Occupational Therapists and something they take seriously and value with\nongoing visits.\nFor instance, P01 highlighted how notes served as a crucial memory aid in ongoing care:\n\u201cIt\u2019s definitely a burden in some sense, because it does take quite a bit of time to get those notes done,\nbut I find the notes that I write as sole valuable when I go see that family again. So when I\u2019m seeing\nlike 60 families trying to remember who you did what with and like most of our kids are two, three\nyears of age. \u201d -P01\nAnother clinician reflected on the personal voice embedded in documentation, expressing concern about AI-generated\ntext lacking their distinctive tone:\n\u201cLike even in an objective way where I\u2019m stating objective, like you know I\u2019m not being biased. Well,\nI\u2019m biased inherently, but you\u2019re trying to be objective, you\u2019re showing measure like you\u2019re reporting.\nIt still has your person like, it has your sound to it. And so when you\u2019re reading and it doesn\u2019t have\nyour sound, like this is wild. \u201d -P08\nA consistent thread across interviews was a concern with how time is structured and constrained, rather than with\ndocumentation itself. Many felt they lacked sufficient time to effectively balance the direct and indirect tasks required to\ndeliver high-quality care. Several clinicians, particularly those in the School-Based program, noted that organizational\npolicies limited their ability to create notes that added value beyond regulatory requirements. For example, P08\ndescribed how institutional expectations around formatting and dissemination reduced their motivation to engage deeply\nwith the documentation:\n\u201c...if I\u2019ve done my documentation that day and kept up on it, I have to do it again in these visit notes\nand our process to disseminate them is annoying. So not only is writing them annoying, but getting\nthem out is annoying or has historically been annoying and therefore I don\u2019t like to do them. But the\nother thing that like because of the way these are structured and the way they are sent out, it\u2019s just as\nfast for me to write an email and that\u2019s how parents wanna read it. \u201d -P08\nOne factor contributing to clinicians\u2019 feelings of overwhelm and burnout appears to be the recent transition to a new\nhealth record platform and the complexities associated with documenting within it. While intended to streamline\nworkflows, many clinicians found the system clunky and inefficient\u2014particularly when completing notes that required\nduplicating information across multiple forms. For example, many clinicians noted that completing notes often involves\nrepetitive clicking to input each component of a SOAP note, which they found both frustrating and time-consuming.\nOne clinician described this repetitive structure as a fundamental barrier to efficiency:\n\u201cSo you\u2019ve got the pre-assessment form, you\u2019ve got a soap note and you\u2019ve got a consent form that\nare all documenting the same interaction. \u201d -N03\nAnother clinician reflected on how the platform\u2019s inefficiencies compounded existing frustrations but reinforced that\nwriting notes, in itself, wasn\u2019t the issue:\n\u201cYeah, I think, I mean, I think it further like confirms that [EHR SOFTWARE] is extremely inefficient,\nlike there\u2019s inefficiencies built into a lot of our processes, which are getting in the way of us being\nefficient, but actually our ability to write the notes isn\u2019t necessarily [THE PROBLEM] Right?\u201d -P05\nTogether, these reflections complicate the assumption that LLMs simply need to automate SOAP notes to be useful. As\nparticipants emphasized, the real barriers to efficiency lie in systems, structures, and workflows that shape how, when,\nand why documentation gets done.\n7\n\n--- Page 8 ---\nAPREPRINT - SEPTEMBER 5, 2025\n4.3 Theme 3: Flexibility of Proposed Tools and Promoting Clinician Autonomy\nA strong theme that emerged was clinicians\u2019 dedication to their work and the sense of professional identity they brought\nto how they performed it. Many participants had years of experience and had developed highly individualized workflows\nand informal tools to manage both direct and indirect aspects of care. Among these were customized documentation\ntemplates and strategies that they had refined over time. For example, several clinicians described how they maintained\nexternal resources\u2014such as written prompts or structured text banks\u2014outside of the official clinical record to make\ndocumentation more efficient and personally meaningful. As one participant explained:\n\u201cI feel like I mean some of it is changing with the forms, but we\u2019ve all had kind of our own little\ntemplates of things that we would use to support our documentation. \u201d -N01\nAnother clinician elaborated on the cognitive benefits of these personalized prompts:\n\u201cI\u2019ve always lived with templates outside of the clinical record because I found that they have been\nthe most efficient for me. They helped to prompt my memory of what I need to ask, what I need to say,\nwhat I need to write\u201d -N02\nThese reflections echo themes from earlier in the analysis, particularly the heterogeneity of documentation workflows\ndescribed in Theme 1. Yet here, clinicians emphasized the value of autonomy in shaping these workflows, adapting\nthem in real time to meet client needs. For example, even if a clinician typically relies on a specific tool during a session,\nthey may choose to forgo it if they believe it could negatively impact the client\u2019s experience. In such cases, they may\nconclude sessions without the usual steps that support their documentation workflow.\nThis adaptive flexibility also shaped clinicians\u2019 perceptions of the LLM documentation tool piloted in the study. While\nmany began the trial with high hopes, several felt that the tool did not yet align with their needs or standards. One Early\nYears clinician reflected on their disappointment:\n\u201cHonestly, for me, I was hoping for a better outcome like for me was a bit disappointing. I was really\nwanting it to be helpful and a little bit more efficient for me and then I just, I don\u2019t know if I think\nwe\u2019ll get there for me it\u2019s not ready, It\u2019s not ready for where I think it needs to be, so for me it was. \u201d\n-P01\nTo thrive in this environment, clinicians need the autonomy to determine when and how to use tools that support their\ndocumentation practices. During the pilot, several clinicians expressed that there were situations in which the use of\nLLMs did not feel appropriate for the specific context, yet they felt pressured to integrate them into their workflow. As\nthe pilot progressed, some participants began selectively disengaging from the tool\u2019s structured workflow. One therapist\n(P02) described situations where they intentionally bypassed the LLM system, especially when feeling overwhelmed:\n\u201cYes, I would say a lot of the time with [the LLM tool], I ended up doing that maybe like 50 to 75% of\nthe time I was doing it for myself because just the when the notes came through, if I was, like flustered\nwith something else I was like, hey, I\u2019m just gonna do this on my own because, like, I don\u2019t have the\nenergy to, like, go through and fix this note again. \u201d -P02\nRather than signaling disinterest in AI altogether, these decisions often reflected a desire for more control. Sev-\neral clinicians expressed curiosity about how generative AI might be integrated more usefully into their broader\nworkflows\u2014particularly when they had flexibility in how the technology was used.\nThis openness to experimentation extended beyond SOAP notes. Clinicians who were less invested in the pilot\u2019s primary\ngoal still imagined other ways LLMs could support their work, including automating family-facing documentation or\nhelping create personalized resources for clients.\nAs one clinician summarized:\n\u201cI know you\u2019re focused on documentation, but I see some huge advantages for helping clients to\novercome barriers, be more successful in you know their life and their goals. \u201d -N01\nThese reflections reinforce the notion that tool usability alone is not enough. Meaningful adoption of LLMs in clinical\npractice will depend on whether the systems promote, and not constrain, clinician autonomy and align with the\nindividualized, context-sensitive nature of care.\n8\n\n--- Page 9 ---\nAPREPRINT - SEPTEMBER 5, 2025\n4.4 Theme 4: Learning on Both Sides\nAs discussed in Theme 3, clinicians showed a strong interest in exploring potential applications of LLMs beyond the\nprescriptive documentation use case. While the pilot focused on converting scratch notes into SOAP notes, several\nparticipants experimented with broader applications, testing the limits of the tool and imagining alternative integrations\n(see Key Point 1, Table 5). These clinicians expressed excitement about the long-term potential of LLMs\u2014particularly\nif they could be shaped to fit their individualized workflows. For example, one clinician envisioned a tool that could not\nonly transcribe input but intelligently organize it into clinical formats:\n\u201cIt\u2019s the repetitive process, like if I had a smart notebook that I could write some things down and it\nputs it into typed like that would be great. But also like, yeah, if it could somehow integrate that into\nmy template like ohh it knows that this is like a subjective thing or it knows that this thing is goes into\nthe objective category, this part goes into analysis like how cool would that be?\u201d -N02\nDespite this curiosity, the pilot\u2019s input method, where the clinicians were asked to input raw scratch notes, posed\nbarriers. Scratch note practices varied significantly across participants: some used full sentences, others employed\nshorthand or symbols, and some relied entirely on memory. This variability made standardized inputs difficult, leading\nto mixed results. As expected, clinicians whose habits already aligned with the input assumptions of the tool adapted\nmore easily than those whose workflows diverged.\nIn order to participate, some clinicians, particularly those who typically relied on sparse or no scratch notes, created a new\nintermediary artifact: refined notes written solely for use with the LLM. This additional step disrupted their established\nroutines and introduced inefficiencies. When asked about the importance of scratch notes, participants consistently\nemphasized that scratch notes serve a singular, simple purpose: to support accurate post-session documentation. These\nnotes are typically informal, not saved, and rarely revisited. Formalizing them as part of the pilot process fundamentally\naltered how they were produced, leading to frustration. Rather than change their in-session practices, many clinicians\nchose to create an extra, more polished version of their notes specifically for the system.\n\u201cI\u2019m like this is too much effort for me to tell you what to do. I already know what I wanna do, so I\nwould just use my own note like I would just abandon it altogether because it was like this is taking\nme too long in terms of what I want this note to look like. \u201d -P01\nAnother participant echoed this, explaining that the cognitive load of preparing model-friendly inputs nullified any\nbenefit:\n\u201cI would just end up like scribbling notes. So, then to take that information and type it, it was sort\nof like a may as well, if I\u2019m typing it anyways, I may as well just type it into SOAP format, right?\nSo and then or if I do a phone call that I do tend to type, but as I type, I kind of organize it like sort\nof anyways. So I think, yeah, I found it didn\u2019t actually really save me time and I ended up editing\neverything to go back to my usual format. \u201d -P05\nMany clinicians expressed skepticism that the model could handle their typical scratch notes, leading them to write much\nmore detailed input than usual. In many cases, rather than submitting authentic scratch notes, clinicians preemptively\nwrote content that resembled finalized SOAP notes and used those as inputs. Ironically, this strategy transformed the\nLLM into a formatting assistant rather than a generative tool and often eliminating any time savings. This shift was\nespecially apparent when participants were testing the bespoke model trained on historical documentation pairs, where\nclinicians feared minimal input might lead to hallucinations or clinical inaccuracies:\n\u201cSometimes I put it into like SOAP format a little bit... but sometimes it was kind of in sections but it\njust didn\u2019t have the headings, which probably confused it. But yeah, I think I varied\u2014like sometimes\nI would sort of do it as a SOAP , put it in and say like, see what it gives me. But then things ended up\ngetting kind of shifted around and so I would kind of revert back to what I did before. \u201d \u2014P05\nThis lack of trust reflects a deeper misalignment between clinician expectations and system capabilities. Many\nparticipants expressed discomfort with the idea that an AI system could or should contribute substantively to clinical\ndocumentation. This was rooted in concerns about professional responsibility, legal risk, and patient trust:\n\u201cNo, I mean like parents come to come to us because they like you\u2019re the expert, you know what we\u2019re\ndoing? And I don\u2019t know how they would feel if I said \u2019Yeah, some computer model generated these\nrecommendations\u2019. \u201d -P01\n9\n\n--- Page 10 ---\nAPREPRINT - SEPTEMBER 5, 2025\nThe AI systems also struggled when inputs deviated from what they had been trained or tuned to expect. Several\nclinicians reported that models miscategorized content or omitted key information:\n\u201cLike it just kind of would put stuff in areas in the headings that it didn\u2019t belong. So then I would have\nto go through and edit it and then it would put nothing in my subjective even though a lot of my notes\nare like heavily subjective because it\u2019s like updates from family and then it would put it all in like the\nplan which isn\u2019t where it\u2019s supposed to go. \u201d -P02\n\u201cI found that it just caused a lot of errors in writing. So, like sometimes if you said like the child was\nanxious, it would change it to the child has anxiety and like that\u2019s a big known like I can\u2019t say that. \u201d\n-P03\n\u201cI found it mixed things up a lot like it was only subjective report and then it was saying that I observed\ncertain things or sometimes they\u2019re just random information in there that was not I\u2019m like relevant or\nI found sometimes you know, like I put OT recommendations and listed things I recommend and those\nwere like, gone with both models. \u201d -P04\nBeyond the technical issues, participants raised concerns about the burden of adopting new tools in already demanding\nclinical environments. Several clinicians noted that they simply lacked the time or cognitive bandwidth to meaningfully\nengage with the pilot while maintaining their usual responsibilities. Despite these challenges, some clinicians remained\nopen to the idea of AI as a thought partner\u2014not just a documentation assistant.\nAs one clinician speculated:\n\u201cAnd I was like, this is really interesting. I remember saying to him at that time, like in some ways, like\nI think it could skew your information, but I also feel like\u2014I wonder if we could learn from it. In that,\nlike, when they\u2019re doing an analysis and stuff like that, is it going to think of things that I wouldn\u2019t\nhave thought of?\u201d \u2014N02\nThis comment illustrates a subtle but important shift: a move from viewing AI as a documentation tool toward viewing\nit as a potential clinical collaborator.\n5 Discussion\nOur findings show that clinician responses and experiences with AI-assisted documentation cannot be fully explained by\nthe technical capacity of the systems alone. Instead, these responses are shaped by a web of social, organizational, and\ntechnical factors, as well as the fit between them. To interpret our results, we draw on the FITT framework [Ammenwerth\net al., 2006], which conceptualizes technology adoption as a function of the alignment\u2014or misalignment\u2014between\nindividual users, the tasks they perform, and the technology they are asked to adopt. This framework positions\nsociotechnical fit as a continuum, highlighting the interactions between each of the three objects.\nWe organize this discussion using the FITT framework, with one section each for Individuals and Organizational\nContext, Task Complexity and Variation, and Technology Design and Assumptions. We conclude with an analysis of\nhow misalignments across these elements produced integration challenges and what this implies for the deployment of\nLLMs in healthcare.\n5.1 Individuals and Organizational Context (Individual Dimension)\nFrom a social lens, it is essential to recognize that users of clinical documentation systems operate within diverse\npersonal and professional contexts. Each clinician brings a unique combination of preferences, constraints, and\nexperiences to their workflow. These differences may stem from variations in clinical training environments, years of\nprofessional experience, personal stressors, and the specific demands of their practice settings.\nOur analysis underscored the heterogeneity in documentation workflows among clinicians. Importantly, we found no\nsingle optimal approach to completing documentation tasks. Instead, workflows were highly individualized and often\nadapted over time. As such, it is counterproductive to mandate a uniform approach to intermediary tools\u2014such as\nscratch notes\u2014used during documentation. Rather, system design should remain flexible and responsive, enabling\nclinicians to articulate and shape the ways in which AI systems can support their practices.\nAlmost all clinicians we spoke to emphasized their legal obligation to maintain good record keeping through documen-\ntation; however, this meant different things to different individuals. Furthermore, different clinicians have different\n10\n\n--- Page 11 ---\nAPREPRINT - SEPTEMBER 5, 2025\ncomfort levels giving up control of their college mandated documentation. Some clinicians felt that their clinical identity\nwas reflected in their documentation and for others this was not the case.\nClinicians\u2019 approaches to documentation are shaped in part by the training they received throughout their careers,\nwhich varies considerably across individuals. Some clinicians were explicitly trained to use intermediary tools such as\nscratch notes to support documentation whereas others were not, and instead only do what is necessary to create the\nfinal documentation. Within our case study, internal mentorship also played a role in shaping documentation practices.\nSenior clinicians often pass down tools, strategies, and templates to newer staff, contributing to informal but influential\nnorms around documentation.\nOrganizational policies were also highlighted as a major barrier to successful participation and uptake of the proposed\nAI systems. Two features were prominently highlighted here: (1) the number of documentation artefacts that is required\nand (2) the recent transition to the new electronic health record platform. Both factors contribute to a broader perception\namong clinicians that current documentation practices are inefficient and burdensome. Participants expressed that these\nchallenges could be improved through review of organization policy that minimizes the number of tasks required and\nreanalysis of workflows for documentation in the prescribed platform. These concerns were particularly pronounced\namong clinicians in School-Based Programs, where the requirement to generate multiple documentation artefacts was\ncommonly cited.\nAdditional barriers were highlighted for the School-Based program. In our interviews clinicians emphasized the\nextremely dynamic and unpredictable environment in which they deliver therapy. They suggested that this makes it\ndifficult to complete documentation at regular or scheduled intervals. Many clinicians reported that they had insufficient\ntime to complete documentation due to constraints imposed by the daily variability of their settings\u2014for instance,\nnavigating the expectations of different schools, teachers, or institutional routines.\n5.2 Task Complexity and Variation (Task Dimension)\nAlthough documentation is often described as a routine or low-risk area for incorporating AI, our findings show that it\nis far from standardized in practice. The nature of clinical documentation varies significantly depending on the setting,\nprogram, clinician role, and even client type. Within the FITT framework, such variation reflects the complexity of the\ntask itself.\nIn this study, the task of transforming scratch notes into SOAP notes was assumed to be consistent across contexts.\nHowever, this assumption did not hold. In the Early Years program, clinicians had access to tools and time to create\nmore structured scratch notes during sessions. In contrast, clinicians in School-Based programs often delivered care in\nunpredictable classroom environments and rarely produced structured notes until much later, if at all.\nScratch notes were also not uniformly understood across the organization. Some clinicians used shorthand memory\naids, while others relied on mental recall. There was no shared standard for what constitutes a high quality scratch note\nor how it should be used. This heterogeneity in intermediary artifacts directly impaired the perceived relevance and\nusefulness of LLM-based tools.\n5.3 Technology Design and Embedded Assumptions (Technology Dimension)\nThe third FITT component\u2014technology\u2014considers how well a system\u2019s capabilities and constraints align with user\nexpectations and task requirements [Ammenwerth et al., 2006]. In this case, many of the technical challenges presented\nby participants arose from pilot design assumptions that did not align with their actual workflows. This is a commonly\ndocumented phenomenon in AI systems known as the translation gap, where systems that perform well in highly\ncontrolled, benchtop settings fail to deliver similar results with real users upon deployment. When developing an AI\nsystem, the practitioner embeds inductive biases into the system through the modelling decisions they make. In the case\nof the LLM pilot program, several assumptions may have contributed to the relatively low clinician enthusiasm for\nusing the tools.\nThe ability of AI systems to work within a wide variety of environments is known as the model\u2019s capacity to generalize.\nThe structure of the pilot implicitly assumed that input and output formats were sufficiently consistent across the\norganization and among clinicians. However, our analysis highlighted significant heterogeneity in both documentation\npractices and clinical roles at the partner organization, suggesting that a single AI system is unlikely to support\ndocumentation workflows organization-wide. In particular, the program in which a clinician works has a significant\nimpact on both the input (i.e., scratch note) and the required output documentation (e.g., SOAP note, visit note). This\nvariation makes it difficult to design a model that performs well across all scenarios\u2014especially in the absence of\nadditional context indicating that scratch notes may be sparse or formatted differently than the examples used during\ntraining.\n11\n\n--- Page 12 ---\nAPREPRINT - SEPTEMBER 5, 2025\nOne of the most significant inductive biases embedded during AI system training is the selection of specific training\ndata. In the case of the bespoke LLM fine-tuned on historical scratch\u2013SOAP pairs, an implicit assumption about what\nconstitutes a \u201cgood\u201d scratch input and a corresponding SOAP output was reinforced. Our analysis suggests that this\nmay have posed challenges for clinicians, as there are no explicit organizational standards for what a scratch note\nshould include\u2014or whether such notes should be created at all. Additionally, clinicians held varying perspectives on\nwhat makes a high-quality SOAP note. When either of these expectations diverged from the examples provided during\nfine-tuning, the model often failed to perform as intended.\nFor the general-purpose model, Copilot, it is important to recognize that these systems were not trained with clinical\ndocumentation in mind. They were developed using general-purpose internet text, which means that while fewer\ninductive biases were embedded, the models also offered less guidance on what was or was not appropriate. The only\ncontext available to the model came through direct prompting.\nBoth models operated under the assumption that clinicians would provide an intermediary document in the form of\na scratch note containing meaningful information to support LLM-generated documentation. However, when this\nassumption did not hold, many clinicians introduced an additional step of reformatting or rewriting their scratch notes\nto better align with what they believed the model required. In some cases, this involved providing excessive detail and\neffectively completing the SOAP generation process manually before even inputting the note into the model.\n5.4 Misalignment and Integration Failures\nThe full picture of adoption became more clear when we considered how these three dimensions interact, not how any\nsingle one behaves in isolation. The FITT framework emphasizes that integration depends on the degree of fit between\nindividuals, tasks, and technology [Ammenwerth et al., 2006]. In our study, misalignment at multiple intersections led\nto breakdowns in adoption and integration.\nFirst, there was poor Technology\u2013Task fit : the tools assumed structured scratch notes, but clinicians\u2019 inputs were often\nsparse, informal, or nonexistent. Second, there was weak Technology\u2013Individual fit : some clinicians felt the tool\nundermined their control over professional documentation, or demanded extra work without sufficient benefit. Finally,\nthere were strains in Individual\u2013Task fit , as clinicians had varied ideas about what good documentation meant and how\nmuch effort it warranted.\nThese misalignments created friction that revealed a lack of true workflow integration. Clinicians adapted by reformatting\nnotes or supplying overly detailed inputs, often in an effort to improve system performance. This overcompensation\nreflected a trust calibration issue: clinicians overestimated the AI\u2019s capabilities and adjusted their behavior accordingly,\nbut the system wasn\u2019t designed to handle such inputs. As a result, rather than reducing effort, the tools often introduced\nadditional work and complexity.\nA critical sociotechnical issue was the value misalignment between what clinicians wanted from AI assistance and what\nthe tools provided. Clinicians varied in their comfort levels with AI supported documentation. This disconnect shows\nhow the technology addressed aspects of documentation that clinicians valued as part of their professional identity\nrather than automating the truly burdensome administrative tasks.\nThe concept of change fatigue was also apparent in our analysis, as the AI implementation occurred shortly after the\ntransition to the the new electronic health record platform. This timing created additional resistance, with clinicians\nfeeling overwhelmed by consecutive technological changes without sufficient adaptation time. This illustrates how\norganizational context significantly influences technology adoption regardless of the tool\u2019s technical capabilities.\nWe observed a mismatch in adaptation between users and the technology. Clinicians, in an effort to support system\nperformance, often introduced an additional step of creating more structured or \u201crefined\u201d scratch notes specifically for\nthe AI tools. While this demonstrated clinicians\u2019 willingness to adapt, the AI systems were not designed to handle the\ndiversity of these modified formats.\n6 Conclusion\nThis study set out to examine whether LLMs could assist clinicians in one of the most routine and structured documenta-\ntion tasks in healthcare: generating SOAP notes. Despite the narrow scope and low-risk nature of this pilot, our findings\nuncovered persistent sociotechnical barriers that complicate the integration of generative AI into clinical workflows.\nDrawing on qualitative analysis and the FITT framework [Ammenwerth et al., 2006], we observed that successful\nadoption hinged not solely on technical performance, but on the complex interplay between individuals, tasks, and\ntechnology. Clinicians varied in their professional training, clinical contexts, and expectations of what documentation\n12\n\n--- Page 13 ---\nAPREPRINT - SEPTEMBER 5, 2025\nshould achieve. The task itself, often framed as standard, was in practice deeply contextual, shaped by organizational\ndemands, time pressures, and personal documentation habits. In contrast, the LLM tools operated on idealized\nassumptions about user behavior, note structure, and workflow uniformity\u2014assumptions that failed to hold in the\nreal-world environment.\nWhat emerged was a portrait of clinical documentation as a sociotechnical task. The heterogeneity of clinical\nworkflows, varying documentation requirements across programs, and distinct individual preferences all contributed\nto an environment where a one-size-fits-all AI solution is unable to succeed. This analysis highlights the challenges\nclinicians face extend beyond the documentation process itself to include organizational policies, workflow inefficiencies,\nand technology integration issues that cannot be solved by AI tools in isolation. AI tools that fail to account for this\ncomplexity risk not only low adoption but also erosion of professional trust.\nTo move forward, we argue for a more holistic strategy to deploying and developing LLMs for clinical workflows and\ndocumentation. These deployment strategies must balance technological innovation with flexibility, clinician autonomy,\nand organizational readiness. This includes building adaptable tools that can respond to diverse workflows, investing in\nclinician-facing AI literacy, and fostering ongoing collaboration among clinicians, developers, and administrators.\nWe present the case of pediatric occupational therapy documentation not as an isolated incident, but as an early warning.\nIf we are still struggling to integrate LLMs into something as well-scoped and \u201csimple\u201d as note-generation, we must\nquestion its readiness for more complex and higher-risk applications. This study highlights that successful integration\ndepends not just on what current models are able to do, but on how well it aligns with the realities of clinical work.\nResponsible deployment in healthcare needs to start with a better understanding of the people, practices, and systems\nthese tools are meant to support.\n7 Acknowledgments\nThis research was supported by KidsAbility and Mitacs. We thank Brendan Wylie-Toal, Ilona Koshy, Nikita Gaikwad,\nthe KidsAbility Innovation Team, and the participating clinicians for their collaboration and valuable insights.\nReferences\nSolomon Amenyo, Maura R Grossman, Daniel G Brown, and Brendan Wylie-Toal. Assessment of AI-generated\npediatric rehabilitation SOAP-note quality. arXiv [cs.HC] , February 2025.\nElske Ammenwerth, Carola Iller, and Cornelia Mahler. IT-adoption and the interaction of task, technology and\nindividuals: a fit framework and a case study. BMC Med. Inform. Decis. Mak. , 6(1):3, January 2006.\nAnjanava Biswas and Wrick Talukdar. Intelligent clinical documentation: Harnessing generative AI for patient-centric\nclinical note generation. arXiv [cs.AI] , May 2024.\nVirginia Braun and Victoria Clarke. Using thematic analysis in psychology. Qualitative research in psychology , 3(2):\n77\u2013101, 2006.\nVirginia Braun and Victoria Clarke. Successful qualitative research: A practical guide for beginners. 2013.\nDana Brin, Vera Sorin, Akhil Vaid, Ali Soroush, Benjamin S Glicksberg, Alexander W Charney, Girish Nadkarni, and\nEyal Klang. Comparing ChatGPT and GPT-4 performance in USMLE soft skill assessments. Sci. Rep. , 13(1):16492,\nOctober 2023.\nValerie K B\u00fcrger, Julia Amann, Cathrine K T Bui, Jana Fehr, and Vince I Madai. The unmet promise of trustworthy AI\nin healthcare: why we fail at clinical translation. Front. Digit. Health , 6:1279629, April 2024.\nS M Cahill and S Beisbier. Occupational therapy practice guidelines for children and youth ages 5\u201321 years. The\nAmerican Journal of Occupational Therapy , 74(4):7404397010p1\u20137404397010p48, 2020.\nRachel DiMaio. Creation of a custom language model for pediatric occupational therapy documentation. Thesis, 2024.\nFaiza Farhat. ChatGPT as a complementary mental health resource: A boon or a bane. Ann. Biomed. Eng. , 52(5):\n1111\u20131114, May 2024.\nPresenter: Crystal A Gateley. Tips for effective occupational therapy documentation: Using the SOAP note method,\n2015.\nJiyeon Han, Jimin Park, Jinyoung Huh, Uran Oh, Jaeyoung Do, and Daehee Kim. AscleAI: A LLM-based clinical note\nmanagement system for enhancing clinician productivity. In Extended Abstracts of the CHI Conference on Human\nFactors in Computing Systems , pages 1\u20137, New York, NY , USA, May 2024. ACM.\n13\n\n--- Page 14 ---\nAPREPRINT - SEPTEMBER 5, 2025\nYingzhuo Ma, Yi Zeng, Tong Liu, Ruoshan Sun, Mingzhao Xiao, and Jun Wang. Integrating large language models in\nmental health practice: a qualitative descriptive study based on expert interviews. Front. Public Health , 12:1475867,\nNovember 2024.\nEthan Mollick. Making AI work: Leadership, lab, and crowd. https://www.oneusefulthing.org/p/\nmaking-ai-work-leadership-lab-and , May 2025. Accessed: 2025-5-23.\nJasmine Chiat Ling Ong, Shelley Yin-Hsi Chang, Wasswa William, Atul J Butte, Nigam H Shah, Lita Sui Tjien Chew,\nNan Liu, Finale Doshi-Velez, Wei Lu, Julian Savulescu, and Daniel Shu Wei Ting. Ethical and regulatory challenges\nof large language models in medicine. Lancet Digit. Health , 6(6):e428\u2013e432, June 2024.\nPeterson Health Technology Institute AI Taskforce. Adoption of artificial intelligence in healthcare delivery systems:\nEarly applications and impacts, 2025.\nShrirajh Satheakeerthy, Daniel Jesudason, James Pietris, Stephen Bacchi, and Weng Onn Chan. LLM-assisted medical\ndocumentation: efficacy, errors, and ethical considerations in ophthalmology. EYE, 39(8):1440\u20131442, June 2025.\nMatthew Spotnitz, Betina Idnay, Emily R Gordon, Rebecca Shyu, Gongbo Zhang, Cong Liu, James J Cimino, and\nChunhua Weng. A survey of clinicians\u2019 views of the utility of large language models. Appl. Clin. Inform. , 15(2):\n306\u2013312, March 2024.\n14",
  "project_dir": "artifacts/projects/Clinical_Note_Generation_LLM_Evaluation_Framework",
  "communication_dir": "artifacts/projects/Clinical_Note_Generation_LLM_Evaluation_Framework/.agent_comm",
  "assigned_at": "2025-09-06T20:41:32.269766",
  "status": "assigned"
}